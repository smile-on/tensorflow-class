{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series\n",
    "Time Series sequences and prediction of sizonal variations and trends in data by [Laurence Moroney with examples](https://github.com/lmoroney/dlaicourse/tree/master/TensorFlow%20In%20Practice/Course%204%20-%20S%2BP).\n",
    "\n",
    "Time Series :\n",
    "- **Univariate** - single value at each step in time\n",
    "- **Multivariate** - multiple values at each step in time\n",
    "\n",
    "Used as search of patterns in time:\n",
    "- Prediction of future = forecast, past = imputation\n",
    "- Anomaly detection\n",
    "- Feature detection in speach recognition\n",
    "\n",
    "Common patterns in time series:\n",
    "- **trend** constant or linear function\n",
    "- **seasonality** when same patterns repeat at predictable intervals\n",
    "- **combination** of trend and seasonality\n",
    "- **autocorrelation** it correlates with a delayed copy of itself often called a lag.\n",
    "- **white noise** truly random signal can't be predicted.\n",
    "- **Non-stationary** different patterns within different time scope in data.\n",
    "\n",
    "Note **Non-stationary** time series may need few different models (each with limited time scope in data) + anomaly detection.\n",
    "\n",
    "![autocorrelation1](autocorrelation1.jpg)\n",
    "![autocorrelation2](autocorrelation2.jpg)\n",
    "![realmix](realmix.jpg)\n",
    "![non-stationary](non-stationary.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric in timeseries\n",
    "train, test data sets and error measure in TS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Partitions\n",
    "Note difference TS-ML with classical ML:\n",
    "- You whant to include **full cycles** in all sets to avoid bias of diferrent representation in data sets.\n",
    "- tune hyper parameters on validation set\n",
    "- include validation set in training and check final performance on test set\n",
    "- if fianl performance is good before releasing, train production model on whole data set including test, as test has most recent data and more relevant signal for the forecast.\n",
    "\n",
    "![fixed-partitions.jpg](fixed-partitions.jpg)\n",
    "\n",
    "### Rolling Partitions\n",
    "\n",
    "- take small portion of training period and try to predict next day (still inside training set)\n",
    "- add that day to training and try to predict next day\n",
    "- repeat until all training set is used. \n",
    "Monitor model performance on validation set. Model accuracy should gradualy increase.\n",
    "\n",
    "Sometime you don't allocate test set and use next day life data as your test set.\n",
    "\n",
    "![roll-partitions.jpg](roll-partitions.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for evaluating performance\n",
    "\n",
    "L2 metric (MSE) penalizes proportinal to error value, big errors affects function more severly.\n",
    "\n",
    "L1 metric (MAE) does not penalize large errors as much as the mse does. \n",
    "If your gain or your loss is just slightly proportional to the size of the error, then the mae may be better.\n",
    "\n",
    "MAPE - mean absolute percentage error or mape, this is the mean ratio between the absolute error and the absolute value, this gives an idea of the size of the errors compared to the values.\n",
    "\n",
    "```python\n",
    "mae = keras.metrics.mean_absolute_error(y_validation, prediction).numpy()\n",
    "```\n",
    "\n",
    "![](err-metric.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base line (relative performance) - naive forecast, moving average (rolling average), moving average of difference.\n",
    "\n",
    "naive forecast - f(t+1) = f(t)\n",
    "\n",
    "![](relative-performance.jpg)\n",
    "\n",
    "Note, \n",
    "mae(naive forecast) = 5.7\n",
    "mae(moving average) = 7.14\n",
    ",  cause components: trend, seasonality (?). **differencing** is a technique to remove trend, seasonality. So instead of studying the time series itself, we study the difference between the value at time T and the value at an earlier period. Differencing lag.\n",
    "\n",
    "![](differencing1.jpg)\n",
    "\n",
    "base line prediction `f(t) = f(t-lag) + roll_avg(differencing[t, window])`\n",
    "with moving window = 32\n",
    "\n",
    "![](differencing2.jpg)\n",
    "\n",
    "smoth by average 2 with centered window = \\[t-360, t+5 \\]?! for prediction (validation test?) we can't use centered window as we dont know future, use trailing windows.\n",
    "\n",
    "![](differencing3.jpg)\n",
    "\n",
    "Note, \n",
    "mae(naive forecast) = 5.7\n",
    "mae(smooth moving average) = 4.5!\n",
    "\n",
    "statistical forecasting = use linear aproximations in TS (mainly smooth moving average)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
